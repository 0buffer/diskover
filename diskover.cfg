[excludes]
; directory names and absolute paths you want to exclude from crawl, case-sensitive, can include wildcard (.* or tmp* or /dir/dirname* etc)
dirs = .*,.snapshot,.Snapshot
; files you want to exclude from crawl, case-sensitive, can include wildcards (.*, *.doc or NULLEXT for files with no extension)
files = .*,Thumbs.db,.DS_Store,._.DS_Store,.localized,desktop.ini

[elasticsearch]
; uncomment the below three lines if you are using AWS ES
;aws = False
;host = search-diskover-es-cluster-eg3yztrvzb6qucroyyjk2vokza.ap-northeast-1.es.amazonaws.com
;port = 443
; below two lines are for local ES, comment out if you are using AWS ES
host = localhost
port = 9200
; uncomment the below two lines if you installed X-Pack, for http-auth
;user = elastic
;password = changeme
; index name for ES, cli arg overwrites this
indexname = diskover-index
; timeout for connection to ES (default is 10)
timeout = 30
; number of connections kept open to ES when crawling (default is 10)
maxsize = 10
; max retries for ES operations (default is 0)
maxretries = 10
; wait for at least yellow status before bulk uploading (default is False), set to True if you want to wait
wait = False
; chunk size for ES bulk operations (default is 500)
chunksize = 500
; number of shards for index (default is 5)
shards = 5
; number of replicas for index (default is 1)
replicas = 1

[redis]
host = 127.0.0.1
port = 6379
;password =

[paths]
; used by diskover socket server
; path to diskover.py (default is ./diskover.py)
diskoverpath = ./diskover.py
; path to python executable (default is python)
pythonpath = python

[socketlistener]
; hostname and port (TCP) for diskover socket server for remote commands
host = localhost
port = 9999

[dupescheck]
; read size (bytes) for md5 sum check
readsize = 65536

[crawlbot]
; continuous scanner
; time to sleep (seconds) between checking for directory changes
sleeptime = 0.1

[gource]
; should be set to same in diskover-gource.sh
maxfilelag = 0.1
